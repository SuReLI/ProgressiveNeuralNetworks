{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateralBlock(nn.Module):\n",
    "    def __init__(self,col,depth,block,out_shape, in_shapes):\n",
    "        super(LateralBlock,self).__init__()\n",
    "        self.col = col\n",
    "        self.depth = depth \n",
    "        self.out_shape = out_shape\n",
    "        self.block = block\n",
    "        self.u = nn.ModuleList()\n",
    "        \n",
    "        \n",
    "        if self.depth > 0: \n",
    "            self.u.extend([nn.Linear(in_shape,self.out_shape) for in_shape in in_shapes])\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        cur_column_out = self.block(inputs[-1])\n",
    "        prev_columns_out = [mod(x) for mod, x in zip(self.u, inputs)]\n",
    "        res=  F.relu(cur_column_out + sum(prev_columns_out))\n",
    "        return res\n",
    "    \n",
    "        \n",
    "\n",
    "class ProgNet(nn.Module):\n",
    "    def __init__(self,depth):\n",
    "        super(ProgNet,self).__init__()\n",
    "        \n",
    "        self.columns = nn.ModuleList([])\n",
    "        self.depth = depth\n",
    "        \n",
    "    \n",
    "    def forward(self,x,task_id=-1):\n",
    "        assert self.columns\n",
    "\n",
    "        inputs = [col[0](x) for col in self.columns]\n",
    "        for l in range(1,self.depth):\n",
    "            out = []         \n",
    "            for i,col in enumerate(self.columns):\n",
    "                print(\"l {},i {}\".format(l,i))\n",
    "                out.append(col[l](inputs[:i+1]))\n",
    "\n",
    "                inputs = out\n",
    "        return out[task_id]\n",
    "        \n",
    "    def new_task(self,new_layers,shapes):\n",
    "        assert isinstance(new_layers,nn.Sequential)\n",
    "        assert(len(new_layers) == len(shapes))\n",
    "        \n",
    "        task_id = len(self.columns)\n",
    "        idx =[i for i,layer in enumerate(new_layers) if isinstance(layer,(nn.Conv2d,nn.Linear))] + [len(new_layers)]\n",
    "        new_blocks = []\n",
    "        \n",
    "        for k in range(len(idx) -1): \n",
    "            prev_blocks = []\n",
    "            if k > 0: \n",
    "                prev_blocks = [col[k-1] for col in self.columns]\n",
    "                \n",
    "            new_blocks.append(LateralBlock(col = task_id,\n",
    "                                           depth = k,\n",
    "                                           block = new_layers[idx[k]:idx[k+1]],\n",
    "                                           out_shape = shapes[idx[k+1]-1],\n",
    "                                           in_shapes = self._get_out_shape_blocks(prev_blocks)\n",
    "                                          ))\n",
    "        \n",
    "        new_column = nn.ModuleList(new_blocks)\n",
    "        self.columns.append(new_column)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _get_out_shape_blocks(self,blocks):\n",
    "        assert isinstance(blocks,list)\n",
    "        assert all(isinstance(block,LateralBlock) for block in blocks)\n",
    "        return [block.out_shape for block in blocks]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def freeze_columns(self, skip=None):\n",
    "        if skip == None:\n",
    "            skip = []\n",
    "\n",
    "        for i, c in enumerate(self.columns):\n",
    "            if i not in skip:\n",
    "                for params in c.parameters():\n",
    "                    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 609\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Linear(1,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1))\n",
    "shapes = [16,16,32,32,1]\n",
    "params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 0\n"
     ]
    }
   ],
   "source": [
    "pg = ProgNet(5)\n",
    "params = sum(p.numel() for p in pg.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 609\n"
     ]
    }
   ],
   "source": [
    "pg.new_task(net,shapes)\n",
    "params = sum(p.numel() for p in pg.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 1218\n"
     ]
    }
   ],
   "source": [
    "pg.new_task(net,shapes)\n",
    "params = sum(p.numel() for p in pg.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): LateralBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (u): ModuleList()\n",
       "  )\n",
       "  (1): LateralBlock(\n",
       "    (block): Sequential(\n",
       "      (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (u): ModuleList(\n",
       "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (2): LateralBlock(\n",
       "    (block): Sequential(\n",
       "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "    (u): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1,4,3,stride = 1, padding = 1), #out: (B,4,28,28)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(4),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,4,14,14)\n",
    "        nn.Conv2d(4,16,3,stride = 1, padding = 1), #out: (B,16,14,14)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,16,7,7)\n",
    "        nn.Conv2d(16,32,3,stride = 1, padding = 1), #out: (B,32,7,7)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,32,3,3)\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = 32*3*3,out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 128, out_features = 64), \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 64, out_features = 10))\n",
    "\n",
    "shapes = [(4,28,28),\n",
    "          (4,28,28),\n",
    "          (4,28,28),\n",
    "          (4,14,14),\n",
    "          (16,14,14),\n",
    "          (16,14,14),\n",
    "          (16,14,14),\n",
    "          (16,7,7),\n",
    "          (32,7,7),\n",
    "          (32,7,7),\n",
    "          (32,7,7),\n",
    "          (32,3,3),\n",
    "          (128),\n",
    "          (64),\n",
    "          (10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (4): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU()\n",
      "  (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (12): Flatten()\n",
      ")\n",
      "Sequential(\n",
      "  (13): Linear(in_features=288, out_features=128, bias=True)\n",
      "  (14): ReLU()\n",
      "  (15): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Sequential(\n",
      "  (16): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (17): ReLU()\n",
      "  (18): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i,layer in enumerate(net) if isinstance(layer,(nn.Conv2d,nn.Linear))]\n",
    "for k in range(len(idx) -1): \n",
    "    print(net[idx[k]:idx[k+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(net[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,_ = data\n",
    "net(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(1,4,3,stride = 1, padding = 1), #out: (B,4,28,28)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(4),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,4,14,14)\n",
    "        nn.Conv2d(4,16,3,stride = 1, padding = 1), #out: (B,16,14,14)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,16,7,7)\n",
    "        nn.Conv2d(16,32,3,stride = 1, padding = 1), #out: (B,32,7,7)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(2,stride = 2)) #out: (B,32,3,3)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features = 32*3*3,out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 128, out_features = 64), \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 64, out_features = 10))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 51274\n",
      "MyNet(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr = learning_rate)\n",
    "criterion = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.3411\n",
      "epoch [2/10], loss:0.1091\n",
      "epoch [3/10], loss:0.0876\n",
      "epoch [4/10], loss:0.0727\n",
      "epoch [5/10], loss:0.0657\n",
      "epoch [6/10], loss:0.0600\n",
      "epoch [7/10], loss:0.0523\n",
      "epoch [8/10], loss:0.0496\n",
      "epoch [9/10], loss:0.0469\n",
      "epoch [10/10], loss:0.0454\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, y = data\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        y_pred = model(img)\n",
    "        loss = criterion(y_pred, y,reduction = 'mean')\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, train_loss / len(train_loader)))\n",
    "\n",
    "    train_losses.append(train_loss/ len(train_loader))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with ProgNet: fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_column(): \n",
    "    return nn.Sequential(nn.Linear(28*28*1,256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256,128),\n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10))\n",
    "\n",
    "shapes = [256,256,128,128,64,64,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                                     transform = torchvision.transforms.Compose([\n",
    "                                                 torchvision.transforms.ToTensor(),\n",
    "                                                 torchvision.transforms.Normalize(\n",
    "                                                 (0.1307,), (0.3081,))]))\n",
    "\n",
    "data = dataset.data\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = [(dataset.targets ==i).tolist() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase  1 \n",
    "Column 0, digits 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_digits_0_4 = [any(tupl) for tupl in zip(split_idx[0],split_idx[1],split_idx[2],split_idx[3],split_idx[4])]\n",
    "\n",
    "dataset.data = data[mask_digits_0_4]\n",
    "dataset.targets = targets[mask_digits_0_4]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  dataset,\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 242762\n",
      "ProgNet(\n",
      "  (columns): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (1): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (2): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (3): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "prog_net = ProgNet(depth = 4)\n",
    "prog_net.new_task(make_column(),shapes)\n",
    "dummy_net = make_column() \n",
    "\n",
    "params = sum(p.numel() for p in prog_net.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(prog_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(prog_net.parameters(),\n",
    "                       lr = learning_rate)\n",
    "optimizer_d = optim.Adam(dummy_net.parameters(),\n",
    "                       lr = learning_rate)\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.3564\n",
      "epoch [2/10], loss:0.0477\n",
      "epoch [3/10], loss:0.0314\n",
      "epoch [4/10], loss:0.0184\n",
      "epoch [5/10], loss:0.0159\n",
      "epoch [6/10], loss:0.0147\n",
      "epoch [7/10], loss:0.0151\n",
      "epoch [8/10], loss:0.0080\n",
      "epoch [9/10], loss:0.0118\n",
      "epoch [10/10], loss:0.0070\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_losses_d = []\n",
    "prog_net.train()\n",
    "dummy_net.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_loss_d = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, y = data\n",
    "        img = img.view(img.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_d.zero_grad()\n",
    "        # forward\n",
    "        y_pred = prog_net(img)\n",
    "        y_pred_d = dummy_net(img)\n",
    "        loss = criterion(y_pred, y,reduction = 'mean')\n",
    "        loss_d = criterion(y_pred_d, y,reduction = 'mean')\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        loss_d.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_loss_d += loss_d.item()\n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, train_loss / len(train_loader)))\n",
    "\n",
    "    train_losses.append(train_loss/ len(train_loader))\n",
    "    train_losses_d.append(train_loss_d/ len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase 2\n",
    "Column 1, digits 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                                     transform = torchvision.transforms.Compose([\n",
    "                                                 torchvision.transforms.ToTensor(),\n",
    "                                                 torchvision.transforms.Normalize(\n",
    "                                                 (0.1307,), (0.3081,))]))\n",
    "\n",
    "data = dataset.data\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_digits_5_9 = [any(tupl) for tupl in zip(split_idx[5],split_idx[6],split_idx[7],split_idx[8],split_idx[9])]\n",
    "\n",
    "dataset.data = data[mask_digits_5_9]\n",
    "dataset.targets = targets[mask_digits_5_9]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  dataset,\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 284564\n",
      "ProgNet(\n",
      "  (columns): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (1): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (2): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (3): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (u): ModuleList()\n",
      "      )\n",
      "      (1): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "        (u): ModuleList(\n",
      "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "        (u): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (3): LateralBlock(\n",
      "        (block): Sequential(\n",
      "          (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "        )\n",
      "        (u): ModuleList(\n",
      "          (0): Linear(in_features=64, out_features=10, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "prog_net.freeze_columns()\n",
    "prog_net.new_task(make_column(),shapes)\n",
    "\n",
    "params = sum(p.numel() for p in prog_net.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(prog_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(prog_net.parameters(),\n",
    "                       lr = learning_rate)\n",
    "optimizer_d = optim.Adam(dummy_net.parameters(),\n",
    "                       lr = learning_rate)\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 128], m2: [256 x 128] at /tmp/pip-req-build-p5q91txh/aten/src/TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-508-c46190c50b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprog_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0my_pred_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-496-a646a320c800>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, task_id)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-496-a646a320c800>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcur_column_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprev_columns_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_column_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_columns_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 128], m2: [256 x 128] at /tmp/pip-req-build-p5q91txh/aten/src/TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "prog_net.train()\n",
    "dummy_net.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_loss_d = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, y = data\n",
    "        img = img.view(img.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_d.zero_grad()\n",
    "        # forward\n",
    "        y_pred = prog_net(img)\n",
    "        y_pred_d = dummy_net(img)\n",
    "        loss = criterion(y_pred, y,reduction = 'mean')\n",
    "        loss_d = criterion(y_pred_d, y,reduction = 'mean')\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        loss_d.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_loss_d += loss_d.item()\n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, train_loss / len(train_loader)))\n",
    "\n",
    "    train_losses.append(train_loss/ len(train_loader))\n",
    "    train_losses_d.append(train_loss_d/ len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prog-nets-env)",
   "language": "python",
   "name": "prog-nets-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
