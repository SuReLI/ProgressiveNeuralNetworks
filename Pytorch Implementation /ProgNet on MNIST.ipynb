{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgNet(nn.Module):\n",
    "    def __init__(self,depth):\n",
    "        super(ProgNet,self).__init__()\n",
    "        \n",
    "        self.columns = nn.ModuleList([])\n",
    "        self.depth = depth\n",
    "        \n",
    "    \n",
    "    def forward(self,x,task_id=-1):\n",
    "        assert self.columns\n",
    "        inputs = [col[0](x) for col in self.columns]\n",
    "        \n",
    "        for l in range(1,self.depth):\n",
    "            out = []\n",
    "            \n",
    "            for i,col in enumerate(self.columns):\n",
    "                out.append(col[l](inputs[:i+1]))\n",
    "        \n",
    "        return out[task_id]\n",
    "        \n",
    "    def new_task(self):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Linear(1,16),\n",
    "            nn.Linear(16,32),\n",
    "            nn.Linear(32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backend',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_construct',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_item_by_idx',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_tracing_name',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=16, out_features=32, bias=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "img,_ = data\n",
    "print(img[0].view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(1,4,3,stride = 1, padding = 1), #out: (B,4,28,28)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(4),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,4,14,14)\n",
    "        nn.Conv2d(4,16,3,stride = 1, padding = 1), #out: (B,16,14,14)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2,stride = 2), #out: (B,16,7,7)\n",
    "        nn.Conv2d(16,32,3,stride = 1, padding = 1), #out: (B,32,7,7)\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(2,stride = 2)) #out: (B,32,3,3)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features = 32*3*3,out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 128, out_features = 64), \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 64, out_features = 10))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters is: 51274\n",
      "MyNet(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr = learning_rate)\n",
    "criterion = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.3411\n",
      "epoch [2/10], loss:0.1091\n",
      "epoch [3/10], loss:0.0876\n",
      "epoch [4/10], loss:0.0727\n",
      "epoch [5/10], loss:0.0657\n",
      "epoch [6/10], loss:0.0600\n",
      "epoch [7/10], loss:0.0523\n",
      "epoch [8/10], loss:0.0496\n",
      "epoch [9/10], loss:0.0469\n",
      "epoch [10/10], loss:0.0454\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, y = data\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        y_pred = model(img)\n",
    "        loss = criterion(y_pred, y,reduction = 'mean')\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, train_loss / len(train_loader)))\n",
    "\n",
    "    train_losses.append(train_loss/ len(train_loader))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36864"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "288*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.randn(3,5,requires_grad = True) \n",
    "target = torch.randint(5,(3,), dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4914, -0.7180, -2.0485,  1.2676, -0.7600],\n",
       "        [-0.4588,  0.2163,  0.7504, -0.7150,  0.9818],\n",
       "        [ 0.5471, -1.5557, -0.8752,  0.5892, -1.0807]], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_net = nn.Sequential(\n",
    "        nn.Conv2d(1,4,3,stride = 1, padding = 1), \n",
    "        nn.BatchNorm2d(4),\n",
    "        nn.MaxPool2d(2,stride = 2),\n",
    "        nn.Conv2d(4,16,3,stride = 1, padding = 1),\n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2,stride = 2), \n",
    "        nn.Conv2d(16,32,3,stride = 1, padding = 1), \n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.MaxPool2d(2,stride = 2),\n",
    "        nn.Linear(in_features = 32*3*3,out_features = 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 128, out_features = 64), \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(in_features = 64, out_features = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0228, -0.2719, -0.1253],\n",
      "          [ 0.1473, -0.3019, -0.0158],\n",
      "          [ 0.0801,  0.3254,  0.2780]]],\n",
      "\n",
      "\n",
      "        [[[-0.1355,  0.0735,  0.0446],\n",
      "          [-0.2309,  0.0472,  0.0460],\n",
      "          [ 0.3166, -0.1354,  0.1199]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2010, -0.2906,  0.1148],\n",
      "          [-0.0604, -0.2402,  0.1401],\n",
      "          [-0.1778, -0.2526,  0.2906]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2458, -0.1598, -0.3101],\n",
      "          [-0.3148,  0.0281, -0.0030],\n",
      "          [-0.0711,  0.0145,  0.1097]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaxPool2d' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-3fe5f5d90287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq_net\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 591\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaxPool2d' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for layer in seq_net: \n",
    "    print(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prog-nets-env)",
   "language": "python",
   "name": "prog-nets-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
