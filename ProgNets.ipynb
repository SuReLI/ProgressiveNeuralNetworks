{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "size = 100\n",
    "bound = 10\n",
    "x_train = np.random.uniform(0,bound,size).reshape(size,1)\n",
    "y_train = np.floor(x_train).astype('int').reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgNet(tf.keras.layers.Layer):\n",
    "    def __init__(self,layers,U_activation = tf.keras.activations.relu, prev_net=None,name=None):\n",
    "        super(ProgNet,self).__init__(name = name)\n",
    "        \n",
    "        assert prev_net is None or isinstance(prev_net,ProgNet)\n",
    "        assert isinstance(layers,list)\n",
    "        assert all(isinstance(layer, tf.keras.layers.Dense) for layer in layers)\n",
    "        \n",
    "        self.columns = []\n",
    "        self.U = []\n",
    "        self.U_activation = U_activation\n",
    "        self.width = 0\n",
    "        self.depth = len(layers)\n",
    "        \n",
    "        if prev_net is None:\n",
    "            pass\n",
    "        else: \n",
    "            assert len(layers) == prev_net.depth\n",
    "            #TO DO: copy weights from prev net\n",
    "            net_copy = prev_net\n",
    "            \n",
    "            #for layer in net_copy.layers: \n",
    "            #    layer.trainable = False\n",
    "                \n",
    "            self.U = net_copy.U\n",
    "            self.columns = net_copy.columns\n",
    "            self.width = net_copy.width \n",
    "            \n",
    "        \n",
    "        self.columns.append(layers)  \n",
    "        self.width += 1 \n",
    "        #self.U.append([tf.keras.layers.Dense(layer.units,use_bias = False,name='U_' + str(self.width) + ,trainable = True) for layer in self.columns[-1]]\n",
    "        self.U.append([[tf.keras.layers.Dense(layer.units,use_bias = False,name='U_'+str(i)+'_' + str(j),trainable = True) for i,layer in enumerate(layers)] for j in range(self.width-1)])\n",
    "        \n",
    "\n",
    "    def call_h(self,x,i,k):\n",
    "        assert 0 <= i and i < self.depth\n",
    "        assert 0 <= k and k < self.width\n",
    "    \n",
    "        if i == 0: \n",
    "            return self.columns[k][0](x)\n",
    "        else: \n",
    "            if k == 0: \n",
    "                return self.columns[k][i](self.call_h(x,i - 1,k))\n",
    "        \n",
    "            else: \n",
    "                Uh = [self.U[k][j][i](self.call_h(x,i-1,j)) for j in range(k)]\n",
    "                Wh = self.columns[k][i](self.call_h(x,i-1,k))\n",
    "                return self.U_activation(tf.add(tf.add_n(Uh),Wh))\n",
    "    \n",
    "    def call(self,x):\n",
    "        return self.call_h(x,self.depth - 1, self.width-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers1 = [tf.keras.layers.Dense(16,activation = tf.keras.activations.relu,trainable = True),\n",
    "          tf.keras.layers.Dense(32,activation = tf.keras.activations.relu,trainable = True),\n",
    "          tf.keras.layers.Dense(4,activation = tf.keras.activations.relu,trainable = True)]\n",
    "\n",
    "layers2 = [tf.keras.layers.Dense(16,activation = tf.keras.activations.relu,trainable = True),\n",
    "          tf.keras.layers.Dense(32,activation = tf.keras.activations.relu,trainable = True),\n",
    "          tf.keras.layers.Dense(4,activation = tf.keras.activations.relu,trainable = True)]\n",
    "\n",
    "net1 = ProgNet(layers = layers1,name= 'net1')\n",
    "net2 = ProgNet(layers = layers2,prev_net = net1,name = 'net2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72a4678128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72a4678128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72a4678128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72a4678128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72cd23d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72cd23d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72cd23d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProgNet.call of <__main__.ProgNet object at 0x7f72cd23d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None,1])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "bound = 4\n",
    "size = 100\n",
    "x_train = np.random.uniform(0,bound,size).reshape(size,1)\n",
    "expr1 = net1(x)\n",
    "expr2 = net2(x)\n",
    "train_vars1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     \"net1\")\n",
    "train_vars2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     \"net2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0.00283957645 0.069959715 0.031892322]\n",
      " [0 0.00645952672 0.159145445 0.0725491196]\n",
      " [0 0.00812703371 0.200227559 0.0912771225]\n",
      " ...\n",
      " [0 0.0370026231 0.911643 0.415587962]\n",
      " [0 0.0107375905 0.264544457 0.120597057]\n",
      " [0 0.0237074643 0.584089339 0.266267121]]\n",
      "[[0.0523964167 0.0831112713 0 0]\n",
      " [0.119192146 0.189062804 0 0]\n",
      " [0.149960726 0.237867817 0 0]\n",
      " ...\n",
      " [0.682776213 1.08302057 0 0]\n",
      " [0.198130906 0.314275563 0 0]\n",
      " [0.437454432 0.693890929 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.print(expr1),feed_dict = {x: x_train})\n",
    "sess.run(tf.print(expr2),feed_dict = {x: x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'net2_3/Relu_1:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'net2/U_2_0/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2/U_1_0/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_3/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_3/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_4/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_4/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_5/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2/dense_5/bias:0' shape=(4,) dtype=float32>,\n",
       " <tf.Variable 'net2_2/U_2_0/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2_2/U_1_0/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_9/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_9/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_10/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_10/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_11/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2_2/dense_11/bias:0' shape=(4,) dtype=float32>,\n",
       " <tf.Variable 'net2_3/U_2_0/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2_3/U_1_0/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_15/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_15/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_16/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_16/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_17/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net2_3/dense_17/bias:0' shape=(4,) dtype=float32>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables('net2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'net1/dense/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net1/dense/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net1/dense_1/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net1/dense_1/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net1/dense_2/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net1/dense_2/bias:0' shape=(4,) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_6/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_6/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_7/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_7/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_8/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net1_2/dense_8/bias:0' shape=(4,) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_12/kernel:0' shape=(1, 16) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_12/bias:0' shape=(16,) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_13/kernel:0' shape=(16, 32) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_13/bias:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_14/kernel:0' shape=(32, 4) dtype=float32>,\n",
       " <tf.Variable 'net1_3/dense_14/bias:0' shape=(4,) dtype=float32>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables('net1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with ProgNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f8bd0164908>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/dopamine-rl/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f8bd0164860>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/dopamine-rl/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f8bd01645f8>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/dopamine-rl/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f8bd01644e0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/dopamine-rl/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f8bd0164710>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/dopamine-rl/\u001b[0m\n",
      "Requirement already up-to-date: dopamine-rl in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python>=3.4.1.15 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from dopamine-rl) (4.1.1.26)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /home/psaint/.local/lib/python3.6/site-packages (from dopamine-rl) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: gym>=0.10.5 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from dopamine-rl) (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: gin-config>=0.1.1 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from dopamine-rl) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from opencv-python>=3.4.1.15->dopamine-rl) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from absl-py>=0.2.2->dopamine-rl) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle~=1.2.0 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from gym>=0.10.5->dopamine-rl) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from gym>=0.10.5->dopamine-rl) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pyglet<=1.3.2,>=1.2.0 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from gym>=0.10.5->dopamine-rl) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from pyglet<=1.3.2,>=1.2.0->gym>=0.10.5->dopamine-rl) (0.18.1)\n",
      "Collecting cmake\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/34/0a311fedffcc7a153bbc0390ef4c378dbc7f09f9865247137f82d62f8e7a/cmake-3.15.3-py3-none-manylinux2010_x86_64.whl (16.5MB)\n",
      "\u001b[K     |████████████████████████████████| 16.5MB 118kB/s eta 0:00:01     |█████████████████████████       | 12.9MB 141kB/s eta 0:00:26     |██████████████████████████▊     | 13.8MB 143kB/s eta 0:00:20\n",
      "\u001b[?25hInstalling collected packages: cmake\n",
      "Successfully installed cmake-3.15.3\n",
      "Requirement already satisfied: atari_py in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (0.2.6)\n",
      "Requirement already satisfied: numpy in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from atari_py) (1.17.2)\n",
      "Requirement already satisfied: six in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from atari_py) (1.12.0)\n",
      "Requirement already satisfied: gin-config in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages (from gin-config) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# @title Install necessary packages.\n",
    "!pip install --upgrade --no-cache-dir dopamine-rl\n",
    "!pip install cmake\n",
    "!pip install atari_py\n",
    "!pip install gin-config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/dopamine/agents/dqn/dqn_agent.py:98: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/psaint/anaconda3/envs/prog-nets-env/lib/python3.6/site-packages/dopamine/agents/rainbow/rainbow_agent.py:77: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Necessary imports and globals.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from dopamine.agents.dqn import dqn_agent\n",
    "from dopamine.discrete_domains import run_experiment\n",
    "from dopamine.colab import utils as colab_utils\n",
    "from absl import flags\n",
    "import gin.tf\n",
    "\n",
    "BASE_PATH = '/tmp/dqn_with_prognets'  # @param\n",
    "GAME = 'Acrobot'  # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create an agent based on DQN, but choosing actions randomly.\n",
    "\n",
    "LOG_PATH = os.path.join(BASE_PATH, 'dqn', GAME)\n",
    "\n",
    "class ProgNetAgent(dqn_agent.DQNAgent):\n",
    "    def __init__(self, sess, num_actions,net = None):\n",
    "    \"\"\"This maintains all the DQN default argument values.\"\"\"\n",
    "        super(ProgNetAgent, self).__init__(sess, num_actions)\n",
    "        if net is None: \n",
    "            pass\n",
    "        else: \n",
    "            self.network = net\n",
    "\n",
    "\n",
    "def create_prognet_agent(sess, environment, summary_writer=None):\n",
    "    prog_net = Prog\n",
    "  return MyRandomDQNAgent(sess, num_actions=environment.action_space.n)\n",
    "\n",
    "random_dqn_config = \"\"\"\n",
    "import dopamine.discrete_domains.atari_lib\n",
    "import dopamine.discrete_domains.run_experiment\n",
    "atari_lib.create_atari_environment.game_name = '{}'\n",
    "atari_lib.create_atari_environment.sticky_actions = True\n",
    "run_experiment.Runner.num_iterations = 200\n",
    "run_experiment.Runner.training_steps = 10\n",
    "run_experiment.Runner.max_steps_per_episode = 100\n",
    "\"\"\".format(GAME)\n",
    "gin.parse_config(random_dqn_config, skip_unknown=False)\n",
    "\n",
    "# Create the runner class with this agent. We use very small numbers of steps\n",
    "# to terminate quickly, as this is mostly meant for demonstrating how one can\n",
    "# use the framework.\n",
    "random_dqn_runner = run_experiment.TrainRunner(LOG_PATH, create_random_dqn_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gym lib like networks for cartpole/acrobot tasks\n",
    "\n",
    "class CartPoleDQNNetwork(tf.keras.Model):\n",
    "    \"\"\"Keras DQN network for Cartpole.\"\"\"\n",
    "    def __init__(self,num_actions,net):\n",
    "        \"\"\"Builds the deep network used to compute the agent's Q-values.\n",
    "\n",
    "        It rescales the input features so they lie in range [-1, 1].\n",
    "\n",
    "        Args:\n",
    "          num_actions: int, number of actions.\n",
    "          name: str, used to create scope for network parameters.\n",
    "        \"\"\"\n",
    "        super(CartPoleDQNProgNet, self).__init__(name=prog_net.name)\n",
    "        self.net = net\n",
    "\n",
    "    def call(self, state):\n",
    "        \"\"\"Creates the output tensor/op given the state tensor as input.\"\"\"\n",
    "        x = self.net(state)\n",
    "        return atari_lib.DQNNetworkType(x)\n",
    "\n",
    "class CarpoleProgNet(tf.keras.Model):\n",
    "    def __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4       , 5.        , 0.26179939, 6.28318531])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_lib.CARTPOLE_MAX_VALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(num_actions,activation= tf.keras.activations.relu)]\n",
    "cartpole_net = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prog-nets-env)",
   "language": "python",
   "name": "prog-nets-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
